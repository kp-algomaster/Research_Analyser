"""Data models for the Research Analyser pipeline."""

from __future__ import annotations

from dataclasses import dataclass, field
from datetime import datetime
from enum import Enum
from pathlib import Path
from typing import Literal, Optional


class SourceType(str, Enum):
    PDF_FILE = "pdf_file"
    PDF_URL = "pdf_url"
    ARXIV_ID = "arxiv_id"
    DOI = "doi"


class DiagramType(str, Enum):
    METHODOLOGY = "methodology"
    ARCHITECTURE = "architecture"
    RESULTS = "results"


@dataclass
class AnalysisOptions:
    """Configuration for what analysis to perform."""

    extract_text: bool = True
    extract_equations: bool = True
    extract_tables: bool = True
    extract_figures: bool = True
    generate_diagrams: bool = True
    generate_review: bool = True
    generate_audio: bool = False
    generate_summary: bool = True
    generate_storm_report: bool = False
    diagram_types: list[str] = field(
        default_factory=lambda: ["methodology", "architecture"]
    )
    diagram_provider: Literal["openai", "google", "openrouter"] = "google"
    review_dimensions: list[str] = field(
        default_factory=lambda: ["soundness", "presentation", "contribution"]
    )
    output_format: Literal["markdown", "json", "html"] = "markdown"


@dataclass
class PaperInput:
    """Input specification for paper analysis."""

    source_type: SourceType
    source_value: str
    target_venue: Optional[str] = None
    analysis_options: AnalysisOptions = field(default_factory=AnalysisOptions)


@dataclass
class Section:
    """A document section."""

    title: str
    level: int  # Header level (1-6)
    content: str
    subsections: list[Section] = field(default_factory=list)


@dataclass
class Equation:
    """Mathematical equation extracted from paper."""

    id: str
    latex: str
    context: str
    section: str
    is_inline: bool
    label: Optional[str] = None
    description: Optional[str] = None


@dataclass
class Table:
    """Table extracted from paper."""

    id: str
    content: str  # Markdown or HTML table
    caption: Optional[str] = None
    section: str = ""
    rows: int = 0
    cols: int = 0


@dataclass
class Figure:
    """Figure detected in paper."""

    id: str
    image_path: Optional[str] = None
    caption: Optional[str] = None
    section: str = ""
    page: int = 0


@dataclass
class Reference:
    """Bibliography reference."""

    id: str
    text: str
    title: Optional[str] = None
    authors: Optional[list[str]] = None
    year: Optional[int] = None
    venue: Optional[str] = None
    doi: Optional[str] = None


@dataclass
class ExtractedContent:
    """Content extracted from paper via MonkeyOCR."""

    full_text: str
    title: str
    authors: list[str]
    abstract: str
    sections: list[Section]
    equations: list[Equation]
    tables: list[Table]
    figures: list[Figure]
    references: list[Reference]
    reading_order: list[int] = field(default_factory=list)
    metadata: dict = field(default_factory=dict)


@dataclass
class DimensionScore:
    """Score for a single review dimension."""

    name: str
    score: float  # 1-4 scale
    weight: float
    justification: str


@dataclass
class RelatedWork:
    """Related paper found during review."""

    title: str
    authors: list[str]
    url: Optional[str] = None
    relevance_score: float = 0.0
    summary: str = ""


@dataclass
class PeerReview:
    """Structured peer review output."""

    overall_score: float  # 1-10 scale
    confidence: float  # 1-5 scale
    dimensions: dict[str, DimensionScore]
    strengths: list[str]
    weaknesses: list[str]
    suggestions: list[str]
    related_works: list[RelatedWork]
    raw_review: str

    @staticmethod
    def compute_score(
        soundness: float, presentation: float, contribution: float
    ) -> float:
        """Compute final score from dimension scores.

        Formula: score = -0.3057 + 0.7134*S + 0.4242*P + 1.0588*C
        """
        return -0.3057 + 0.7134 * soundness + 0.4242 * presentation + 1.0588 * contribution


@dataclass
class GeneratedDiagram:
    """Diagram generated by PaperBanana."""

    diagram_type: str
    image_path: str
    caption: str
    source_context: str
    iterations: int = 0
    format: str = "png"
    is_fallback: bool = False
    error: str = ""


@dataclass
class KeyPoint:
    """A key finding or contribution from the paper."""

    point: str
    evidence: str
    section: str
    importance: Literal["high", "medium", "low"] = "medium"


@dataclass
class PaperSummary:
    """AI-generated paper summary."""

    one_sentence: str
    abstract_summary: str
    methodology_summary: str
    results_summary: str
    conclusions: str


@dataclass
class ReportMetadata:
    """Metadata about the analysis report."""

    analysed_at: datetime = field(default_factory=datetime.now)
    analyser_version: str = "0.1.0"
    ocr_model: str = "MonkeyOCR-pro-3B"
    diagram_provider: str = "google"
    review_model: str = "gpt-4o"
    processing_time_seconds: float = 0.0


@dataclass
class AnalysisReport:
    """Complete analysis output."""

    paper_input: PaperInput
    extracted_content: ExtractedContent
    review: Optional[PeerReview]
    diagrams: list[GeneratedDiagram]
    summary: PaperSummary
    key_points: list[KeyPoint]
    metadata: ReportMetadata
    storm_report: Optional[str] = None

    def to_markdown(self) -> str:
        """Generate full markdown report."""
        from research_analyser.report_generator import ReportGenerator

        return ReportGenerator().generate_report(self)

    def to_json(self) -> dict:
        """Convert report to JSON-serializable dict."""
        from dataclasses import asdict

        return asdict(self)

    def save(self, output_dir: str) -> None:
        """Save all outputs to directory."""
        from research_analyser.report_generator import ReportGenerator

        ReportGenerator().save_all(self, Path(output_dir))
